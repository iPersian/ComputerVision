{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fbb54700-c769-4bbc-a9bd-fb561d043c8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'url': 'https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/efficientnet_b0_ra-3dd342df.pth', 'hf_hub_id': 'timm/efficientnet_b0.ra_in1k', 'architecture': 'efficientnet_b0', 'tag': 'ra_in1k', 'custom_load': False, 'input_size': (3, 224, 224), 'fixed_input_size': False, 'interpolation': 'bicubic', 'crop_pct': 0.875, 'crop_mode': 'center', 'mean': (0.485, 0.456, 0.406), 'std': (0.229, 0.224, 0.225), 'num_classes': 1000, 'pool_size': (7, 7), 'first_conv': 'conv_stem', 'classifier': 'classifier'}\n",
      "Unpooled shape: torch.Size([2, 1280, 7, 7])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import timm\n",
    "m = timm.create_model('efficientnet_b0', pretrained=True, num_classes=0, global_pool='')\n",
    "print(m.pretrained_cfg)\n",
    "o = m(torch.randn(2, 3, 224, 224))\n",
    "print(f'Unpooled shape: {o.shape}')\n",
    "\n",
    "B, C, W, H = o.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "22be089a-2f6c-421b-8b48-3223f14fe46b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_size': (3, 224, 224), 'interpolation': 'bicubic', 'mean': (0.5, 0.5, 0.5), 'std': (0.5, 0.5, 0.5), 'crop_pct': 0.9, 'crop_mode': 'center'}\n",
      "Compose(\n",
      "    Resize(size=248, interpolation=bicubic, max_size=None, antialias=True)\n",
      "    CenterCrop(size=(224, 224))\n",
      "    MaybeToTensor()\n",
      "    Normalize(mean=tensor([0.5000, 0.5000, 0.5000]), std=tensor([0.5000, 0.5000, 0.5000]))\n",
      ")\n",
      "tensor([ 0.7394,  0.3162, -0.3828, -0.3556, -3.3390, -1.3829, -1.5910, -1.0768,\n",
      "         0.9661, -1.3756], grad_fn=<SliceBackward0>)\n",
      "tensor([ 0.7394,  0.3162, -0.3828, -0.3556, -3.3390, -1.3829, -1.5910, -1.0768,\n",
      "         0.9661, -1.3756], grad_fn=<SliceBackward0>)\n"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlopen\n",
    "from PIL import Image\n",
    "import timm\n",
    "\n",
    "img = Image.open(urlopen(\n",
    "    'https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/beignets-task-guide.png'\n",
    "))\n",
    "\n",
    "model = timm.create_model(\n",
    "    'vit_base_patch16_224.augreg2_in21k_ft_in1k',\n",
    "    pretrained=True,\n",
    "    num_classes=0,  # remove classifier nn.Linear\n",
    ")\n",
    "model = model.eval()\n",
    "\n",
    "o = torch.rand((2, 3, 224, 224))\n",
    "\n",
    "# get model specific transforms (normalization, resize)\n",
    "data_config = timm.data.resolve_model_data_config(model)\n",
    "\n",
    "print(data_config)\n",
    "\n",
    "transforms = timm.data.create_transform(**data_config, is_training=False)\n",
    "\n",
    "print(transforms)\n",
    "\n",
    "output = model(o)  # output is (batch_size, num_features) shaped tensor\n",
    "\n",
    "# or equivalently (without needing to set num_classes=0)\n",
    "\n",
    "output = model.forward_features(transforms(img).unsqueeze(0))\n",
    "# output is unpooled, a (1, 197, 768) shaped tensor\n",
    "\n",
    "print(output[0, 0, :10])\n",
    "\n",
    "output = model.forward_head(output, pre_logits=True)\n",
    "# output is a (1, num_features) shaped tensor\n",
    "\n",
    "print(output[0, :10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c381b430-a3dd-4fb8-a1e4-498af3d1d42a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jpegs_small\\ARTVU\\132801\n",
      "jpegs_small\\ARTVU\\132802\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from IPython.display import display\n",
    "import pandas as pd\n",
    "\n",
    "jpeg_p = Path(\"jpegs_small\")\n",
    "mask_p = Path(\"masks_small\")\n",
    "\n",
    "df = pd.DataFrame(columns=['masks', 'label'])\n",
    "\n",
    "X = []\n",
    "Y = []\n",
    "\n",
    "dt = 4 # Past images\n",
    "dl = 1 # Future images to predict\n",
    "\n",
    "for folder in jpeg_p.glob(\"*/*\"):\n",
    "    imgs = list(folder.glob(\"*\"))\n",
    "    for i in range(len(imgs) - dt - dl + 1):\n",
    "        # img = imgs[img]\n",
    "        # print(img)\n",
    "        # img_mask = mask_p / Path(*img.parts[1:])\n",
    "        # print(img_mask)\n",
    "        # display(Image.open(img))\n",
    "        # display(Image.open(img_mask))\n",
    "\n",
    "        x = \",\".join(str(img) for img in imgs[i: i+dt])\n",
    "        y = imgs[i + dt + dl - 1]\n",
    "        X.append(x)\n",
    "        Y.append(y)\n",
    "\n",
    "new_row = pd.DataFrame({'masks': X, 'label': Y})    \n",
    "df = pd.concat([df, new_row], ignore_index=True)\n",
    "df.to_csv('output.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c268b4ea-a8ca-4e6e-aca4-82185f0da173",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Local)",
   "language": "python",
   "name": "local-python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
