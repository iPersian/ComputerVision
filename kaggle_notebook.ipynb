{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11251413,"sourceType":"datasetVersion","datasetId":7030976},{"sourceId":11257002,"sourceType":"datasetVersion","datasetId":7035236},{"sourceId":11267817,"sourceType":"datasetVersion","datasetId":7043423}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nfrom pathlib import Path\nimport numpy as np\nimport pandas as pd\nfrom PIL import Image\nimport torch\nimport torch.nn as nn\nimport timm\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.optim import AdamW\nfrom torch.utils.tensorboard import SummaryWriter\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\nfrom tqdm import tqdm\nimport gc\n\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\n\ntrain_csv_url = \"https://sanaye.nl/dataset/train_4_1.csv\"\ndf_train = pd.read_csv(train_csv_url)\n\nbase_path = Path(\"/kaggle/input/maskss\")\n\ndef file_exists(relative_path):\n    rp_str = relative_path.replace(\"\\\\\", \"/\")\n    rp = Path(rp_str)\n    if rp.parts[0] in [\"masks-small\", \"masks_small\"]:\n        rp = Path(*rp.parts[1:])\n    return (base_path / rp).exists()\n\ndf_train[\"file_exists\"] = df_train[\"label\"].apply(file_exists)\nnum_missing = (~df_train[\"file_exists\"]).sum()\nprint(f\"Training CSV: {len(df_train)} rows, {num_missing} missing files\")\n\ntrain_transform = A.Compose([\n    A.HorizontalFlip(),\n    A.VerticalFlip(),\n    A.RandomRotate90(),\n    A.Transpose(),\n    ToTensorV2()\n])\nval_transform = A.Compose([ToTensorV2()])\n\nclass CustomDataset(Dataset):\n    def __init__(self, df, transforms):\n        self.df = df\n        self.transforms = transforms\n        self.masks_path = Path(\"/kaggle/input/maskss\")\n\n    def _load_image(self, relative_path):\n\n        rp_str = relative_path.replace(\"\\\\\", \"/\")\n        rp = Path(rp_str)\n\n        if rp.parts[0] in [\"masks-small\", \"masks_small\"]:\n            rp = Path(*rp.parts[1:])\n        full_path = self.masks_path / rp\n        if not full_path.exists():\n            print(f\"Warning: Image not found: {full_path}, returning zero array as placeholder\")\n\n            return np.zeros((224, 224), dtype=np.uint8)\n        return np.asarray(Image.open(full_path))\n\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, item):\n        inputs, label = self.df.iloc[item][[\"masks\", \"label\"]]\n        input_paths = [p.strip() for p in inputs.split(\",\")]\n        label_img = self._load_image(label)\n        input_imgs = [self._load_image(img) for img in input_paths]\n        if self.transforms:\n            input_imgs = [self.transforms(image=img)[\"image\"] / 255 for img in input_imgs]\n            label_img = self.transforms(image=label_img)[\"image\"] / 255\n        return torch.stack(input_imgs, dim=0).squeeze(1), label_img\n\ntraining_ds = CustomDataset(df_train, train_transform)\n\ndef get_training_ds():\n    return training_ds\n\n# Defines the model\nclass DoubleConv(nn.Module):\n    def __init__(self, in_channels, out_channels):\n        super(DoubleConv, self).__init__()\n        self.double_conv = nn.Sequential(\n            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1, bias=False),\n            nn.BatchNorm2d(out_channels),\n            nn.ReLU(),\n            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1, bias=False),\n            nn.BatchNorm2d(out_channels),\n            nn.ReLU()\n        )\n    def forward(self, x):\n        return self.double_conv(x)\n\nclass Downward(nn.Module):\n    def __init__(self):\n        super(Downward, self).__init__()\n        self.conv1 = DoubleConv(1, 16)\n        self.conv2 = DoubleConv(16, 32)\n        self.conv3 = DoubleConv(32, 64)\n        self.conv4 = DoubleConv(64, 128)\n        self.maxpool = nn.MaxPool2d(2)\n        self.fc = nn.Linear(128 * 28 * 28, 768)\n        self.features = {}\n    def forward(self, x):\n        x = self.conv1(x)\n        self.features['conv1'] = x\n        x = self.maxpool(x)\n        x = self.conv2(x)\n        self.features['conv2'] = x\n        x = self.maxpool(x)\n        x = self.conv3(x)\n        self.features['conv3'] = x\n        x = self.maxpool(x)\n        x = self.conv4(x)\n        B, _, _, _ = x.shape\n        return self.fc(x.reshape(B, -1))\n\nclass Upward(nn.Module):\n    def __init__(self):\n        super(Upward, self).__init__()\n        self.fc = nn.Linear(768, 128 * 28 * 28)\n        self.up1 = nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2)\n        self.up2 = nn.ConvTranspose2d(64, 32, kernel_size=2, stride=2)\n        self.up3 = nn.ConvTranspose2d(32, 16, kernel_size=2, stride=2)\n        self.conv1 = DoubleConv(128, 64)\n        self.conv2 = DoubleConv(64, 32)\n        self.conv3 = DoubleConv(32, 16)\n        self.out = nn.Conv2d(16, 1, kernel_size=3, padding=1, bias=False)\n        self.sigmoid = nn.Sigmoid()\n    def forward(self, x, x_res):\n        x = self.fc(x)\n        B, _ = x.shape\n        x = x.reshape(B, 128, 28, 28)\n        x = self.up1(x)\n        x = torch.cat((x, x_res['conv3']), dim=1)\n        x = self.conv1(x)\n        x = self.up2(x)\n        x = torch.cat((x, x_res['conv2']), dim=1)\n        x = self.conv2(x)\n        x = self.up3(x)\n        x = torch.cat((x, x_res['conv1']), dim=1)\n        x = self.conv3(x)\n        x = self.out(x)\n        return self.sigmoid(x)\n\nclass ViT(nn.Module):\n    def __init__(self, num_frames=4):\n        super().__init__()\n        self.vit = timm.create_model('vit_base_patch16_224', pretrained=True, num_classes=0)\n        del self.vit.patch_embed\n        self.temporal_pos = nn.Parameter(torch.randn(1, num_frames + 1, 768))\n        self.cls_token = self.vit.cls_token\n    def forward(self, x):\n        batch_size = x.shape[0]\n        cls_tokens = self.cls_token.expand(batch_size, -1, -1)\n        x = torch.cat((cls_tokens, x), dim=1)\n        x += self.temporal_pos\n        return self.vit.norm(self.vit.blocks(x))\n\nclass Network(nn.Module):\n    def __init__(self, num_frames=4):\n        super(Network, self).__init__()\n        self.encoders = nn.ModuleList([Downward() for _ in range(num_frames)])\n        self.num_frames = num_frames\n        self.decoder = Upward()\n        self.vit = ViT()\n    def forward(self, x):\n        encoded = [self.encoders[i](x[:, i, :, :].unsqueeze(1)) for i in range(self.num_frames)]\n        x = torch.stack(encoded, dim=1)\n        x = self.vit(x)\n        x = self.decoder(x[:, 0, :], self.encoders[3].features)\n        return x\n\n# IoULoss\nclass IoULoss(nn.Module):\n    def __init__(self):\n        super(IoULoss, self).__init__()\n    def forward(self, x, target):\n        intersection = (x * target).sum((2, 3))\n        union = x.sum((2, 3)) + target.sum((2, 3)) - intersection\n        iou = (intersection + 1e-6) / (union + 1e-6)\n        return 1 - iou.mean()\n\n# Training\ngc.collect()\nif device == 'cuda':\n    torch.cuda.empty_cache()\n\nwriter = SummaryWriter()\n\nepochs = 30\ncriterion = IoULoss().to(device)\nlr = 1e-3\nmodel = Network().to(device)\noptimizer = AdamW(model.parameters(), lr)\n\ndataloader = DataLoader(training_ds, batch_size=8, shuffle=True)\n\ndef train(model, loader, criterion, optimizer, epoch):\n    model.train()\n    avg_loss = 0\n    for idx, (data, target) in enumerate(tqdm(loader, total=len(loader))):\n        data = data.to(device).float()\n        target = target.to(device).float()\n        output = model(data)\n        loss = criterion(output, target)\n        writer.add_scalars(f\"Loss epoch {epoch}\", {'Train': loss.item()}, idx)\n        avg_loss += loss.item()\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n    return avg_loss / len(loader)\n\nprint(\"Loading...\")\nprint(\"Starting training...\")\n\nfor epoch in range(epochs):\n    train_loss = train(model, dataloader, criterion, optimizer, epoch)\n    print(f'Train loss epoch {epoch}: {train_loss}')\n\nstate = dict(model_state=model.state_dict())\ntorch.save(state, 'epoch_30_4_1.pth')\nprint('Finished Training')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-08T00:41:08.714504Z","iopub.execute_input":"2025-04-08T00:41:08.714686Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Validation\nfrom torch.utils.data import DataLoader\n\nval_csv_url = \"https://sanaye.nl/dataset/val_4_1.csv\"\ndf_val = pd.read_csv(val_csv_url)\n\nval_ds = CustomDataset(df_val, val_transform)\nval_loader = DataLoader(val_ds, batch_size=8, shuffle=False)\n\n# Reload model and weights\nmodel = Network().to(device)\ncheckpoint = torch.load(\"/kaggle/working/epoch_30_4_1.pth\", map_location=device)\nmodel.load_state_dict(checkpoint['model_state'])\n\n# Validation\ndef validate(model, loader, criterion):\n    model.eval()\n    avg_loss = 0\n    with torch.no_grad():\n        for data, target in tqdm(loader, total=len(loader)):\n            data = data.to(device).float()\n            target = target.to(device).float()\n            output = model(data)\n            loss = criterion(output, target)\n            avg_loss += loss.item()\n    return avg_loss / len(loader)\n\n# Run validation\nval_loss = validate(model, val_loader, criterion)\nprint(f\"Validation Loss: {val_loss:.4f}\")\n\n# Save validation loss to a text file\nwith open('/kaggle/working/validation_loss.txt', 'w') as f:\n    f.write(f\"Validation Loss: {val_loss:.4f}\\n\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Visualize prediction vs ground truth\nimport random\nimport matplotlib.pyplot as plt\n\n# Pick random sample\nsample_idx = random.randint(0, len(val_ds) - 1)\ninput_tensor, label_tensor = val_ds[sample_idx]\n\n# Move input to device and add batch dimension\ninput_tensor = input_tensor.to(device).unsqueeze(0).float()\nmodel.eval()\nwith torch.no_grad():\n    prediction = model(input_tensor).squeeze(0).cpu()\n    prediction_bin = torch.round(prediction)\n\n# Visualization\ndef plot_mask(mask, title, cmap='gray'):\n    plt.imshow(mask.squeeze().numpy(), cmap=cmap)\n    plt.title(title)\n    plt.axis('off')\n\nplt.figure(figsize=(12, 4))\n\n# Input frames\nfor i in range(4):\n    plt.subplot(2, 4, i + 1)\n    plot_mask(input_tensor[0, i].cpu(), f\"Input Mask {i+1}\")\n\n# Prediction and label\nplt.subplot(2, 4, 5)\nplot_mask(prediction, \"Predicted Mask\")\n\nplt.subplot(2, 4, 6)\nplot_mask(prediction_bin, \"Binarized Prediction\")\n\nplt.subplot(2, 4, 7)\nplot_mask(label_tensor, \"Ground Truth\")\n\n# Difference\nplt.subplot(2, 4, 8)\nplot_mask(prediction_bin - label_tensor, \"Prediction - GT\")\n\nplt.tight_layout()\n\nplt.savefig('/kaggle/working/visualization.png', bbox_inches='tight', dpi=300)\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}